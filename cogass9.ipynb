{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137b8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in /Users/nishthagoyal/Documents/python/venv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1bee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240ae1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nishthagoyal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nishthagoyal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "## The NLTK sentence tokenizer (sent_tokenize) requires a pre-trained model called the Punkt tokenizer for your language \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f15f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nishthagoyal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/nishthagoyal/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bcec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gym isn’t just a place filled with weights and machines — it’s a personal battlefield where each drop of sweat marks a silent victory it’s where the tired become disciplined and stress melts into strength rep after rep among the clinks of iron and the rhythm of breath there’s a quiet transformation happening — not just in bodies but in minds the gym is one of the few places where failure is encouraged even celebrated because it means you’re pushing past limits in a world that demands instant results the gym teaches patience grit and the art of showing up even on the hard days\n"
     ]
    }
   ],
   "source": [
    "text=\"The gym isn’t just a place filled with weights and machines — it’s a personal battlefield where each drop of sweat marks a silent victory. It’s where the tired become disciplined, and stress melts into strength rep after rep. Among the clinks of iron and the rhythm of breath, there’s a quiet transformation happening — not just in bodies, but in minds. The gym is one of the few places where failure is encouraged, even celebrated, because it means you’re pushing past limits. In a world that demands instant results, the gym teaches patience, grit, and the art of showing up, even on the hard days.\"\n",
    "text_lower=text.lower()\n",
    "text_clean=text_lower.translate(str.maketrans('','',string.punctuation))\n",
    "print(text_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b189270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens: ['the', 'gym', 'isn', '’', 't', 'just', 'a', 'place', 'filled', 'with', 'weights', 'and', 'machines', '—', 'it', '’', 's', 'a', 'personal', 'battlefield', 'where', 'each', 'drop', 'of', 'sweat', 'marks', 'a', 'silent', 'victory', 'it', '’', 's', 'where', 'the', 'tired', 'become', 'disciplined', 'and', 'stress', 'melts', 'into', 'strength', 'rep', 'after', 'rep', 'among', 'the', 'clinks', 'of', 'iron', 'and', 'the', 'rhythm', 'of', 'breath', 'there', '’', 's', 'a', 'quiet', 'transformation', 'happening', '—', 'not', 'just', 'in', 'bodies', 'but', 'in', 'minds', 'the', 'gym', 'is', 'one', 'of', 'the', 'few', 'places', 'where', 'failure', 'is', 'encouraged', 'even', 'celebrated', 'because', 'it', 'means', 'you', '’', 're', 'pushing', 'past', 'limits', 'in', 'a', 'world', 'that', 'demands', 'instant', 'results', 'the', 'gym', 'teaches', 'patience', 'grit', 'and', 'the', 'art', 'of', 'showing', 'up', 'even', 'on', 'the', 'hard', 'days']\n",
      "Sentence Tokens: ['the gym isn’t just a place filled with weights and machines — it’s a personal battlefield where each drop of sweat marks a silent victory it’s where the tired become disciplined and stress melts into strength rep after rep among the clinks of iron and the rhythm of breath there’s a quiet transformation happening — not just in bodies but in minds the gym is one of the few places where failure is encouraged even celebrated because it means you’re pushing past limits in a world that demands instant results the gym teaches patience grit and the art of showing up even on the hard days']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "word_tokens=word_tokenize(text_clean)\n",
    "sent_tokens=sent_tokenize(text_clean)\n",
    "print(\"Word Tokens:\", word_tokens)\n",
    "print(\"Sentence Tokens:\", sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b622f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Words: ['gym', '’', 'place', 'filled', 'weights', 'machines', '—', '’', 'personal', 'battlefield', 'drop', 'sweat', 'marks', 'silent', 'victory', '’', 'tired', 'become', 'disciplined', 'stress', 'melts', 'strength', 'rep', 'rep', 'among', 'clinks', 'iron', 'rhythm', 'breath', '’', 'quiet', 'transformation', 'happening', '—', 'bodies', 'minds', 'gym', 'one', 'places', 'failure', 'encouraged', 'even', 'celebrated', 'means', '’', 'pushing', 'past', 'limits', 'world', 'demands', 'instant', 'results', 'gym', 'teaches', 'patience', 'grit', 'art', 'showing', 'even', 'hard', 'days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nishthagoyal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words=set(stopwords.words('english'))\n",
    "filtered_words=[w for w in word_tokens if w.lower() not in stop_words]\n",
    "print(\"Filtered Words:\", filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2c105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym -> Stemmed: gym,LancasterStemmer: gym, Lemmatized: gym\n",
      "’ -> Stemmed: ’,LancasterStemmer: ’, Lemmatized: ’\n",
      "place -> Stemmed: place,LancasterStemmer: plac, Lemmatized: place\n",
      "filled -> Stemmed: fill,LancasterStemmer: fil, Lemmatized: filled\n",
      "weights -> Stemmed: weight,LancasterStemmer: weight, Lemmatized: weight\n",
      "machines -> Stemmed: machin,LancasterStemmer: machin, Lemmatized: machine\n",
      "— -> Stemmed: —,LancasterStemmer: —, Lemmatized: —\n",
      "’ -> Stemmed: ’,LancasterStemmer: ’, Lemmatized: ’\n",
      "personal -> Stemmed: person,LancasterStemmer: person, Lemmatized: personal\n",
      "battlefield -> Stemmed: battlefield,LancasterStemmer: battlefield, Lemmatized: battlefield\n",
      "drop -> Stemmed: drop,LancasterStemmer: drop, Lemmatized: drop\n",
      "sweat -> Stemmed: sweat,LancasterStemmer: swe, Lemmatized: sweat\n",
      "marks -> Stemmed: mark,LancasterStemmer: mark, Lemmatized: mark\n",
      "silent -> Stemmed: silent,LancasterStemmer: sil, Lemmatized: silent\n",
      "victory -> Stemmed: victori,LancasterStemmer: vict, Lemmatized: victory\n",
      "’ -> Stemmed: ’,LancasterStemmer: ’, Lemmatized: ’\n",
      "tired -> Stemmed: tire,LancasterStemmer: tir, Lemmatized: tired\n",
      "become -> Stemmed: becom,LancasterStemmer: becom, Lemmatized: become\n",
      "disciplined -> Stemmed: disciplin,LancasterStemmer: disciplin, Lemmatized: disciplined\n",
      "stress -> Stemmed: stress,LancasterStemmer: stress, Lemmatized: stress\n",
      "melts -> Stemmed: melt,LancasterStemmer: melt, Lemmatized: melt\n",
      "strength -> Stemmed: strength,LancasterStemmer: strength, Lemmatized: strength\n",
      "rep -> Stemmed: rep,LancasterStemmer: rep, Lemmatized: rep\n",
      "rep -> Stemmed: rep,LancasterStemmer: rep, Lemmatized: rep\n",
      "among -> Stemmed: among,LancasterStemmer: among, Lemmatized: among\n",
      "clinks -> Stemmed: clink,LancasterStemmer: clink, Lemmatized: clink\n",
      "iron -> Stemmed: iron,LancasterStemmer: iron, Lemmatized: iron\n",
      "rhythm -> Stemmed: rhythm,LancasterStemmer: rhythm, Lemmatized: rhythm\n",
      "breath -> Stemmed: breath,LancasterStemmer: brea, Lemmatized: breath\n",
      "’ -> Stemmed: ’,LancasterStemmer: ’, Lemmatized: ’\n",
      "quiet -> Stemmed: quiet,LancasterStemmer: quiet, Lemmatized: quiet\n",
      "transformation -> Stemmed: transform,LancasterStemmer: transform, Lemmatized: transformation\n",
      "happening -> Stemmed: happen,LancasterStemmer: hap, Lemmatized: happening\n",
      "— -> Stemmed: —,LancasterStemmer: —, Lemmatized: —\n",
      "bodies -> Stemmed: bodi,LancasterStemmer: body, Lemmatized: body\n",
      "minds -> Stemmed: mind,LancasterStemmer: mind, Lemmatized: mind\n",
      "gym -> Stemmed: gym,LancasterStemmer: gym, Lemmatized: gym\n",
      "one -> Stemmed: one,LancasterStemmer: on, Lemmatized: one\n",
      "places -> Stemmed: place,LancasterStemmer: plac, Lemmatized: place\n",
      "failure -> Stemmed: failur,LancasterStemmer: fail, Lemmatized: failure\n",
      "encouraged -> Stemmed: encourag,LancasterStemmer: enco, Lemmatized: encouraged\n",
      "even -> Stemmed: even,LancasterStemmer: ev, Lemmatized: even\n",
      "celebrated -> Stemmed: celebr,LancasterStemmer: celebr, Lemmatized: celebrated\n",
      "means -> Stemmed: mean,LancasterStemmer: mean, Lemmatized: mean\n",
      "’ -> Stemmed: ’,LancasterStemmer: ’, Lemmatized: ’\n",
      "pushing -> Stemmed: push,LancasterStemmer: push, Lemmatized: pushing\n",
      "past -> Stemmed: past,LancasterStemmer: past, Lemmatized: past\n",
      "limits -> Stemmed: limit,LancasterStemmer: limit, Lemmatized: limit\n",
      "world -> Stemmed: world,LancasterStemmer: world, Lemmatized: world\n",
      "demands -> Stemmed: demand,LancasterStemmer: demand, Lemmatized: demand\n",
      "instant -> Stemmed: instant,LancasterStemmer: inst, Lemmatized: instant\n",
      "results -> Stemmed: result,LancasterStemmer: result, Lemmatized: result\n",
      "gym -> Stemmed: gym,LancasterStemmer: gym, Lemmatized: gym\n",
      "teaches -> Stemmed: teach,LancasterStemmer: teach, Lemmatized: teach\n",
      "patience -> Stemmed: patienc,LancasterStemmer: paty, Lemmatized: patience\n",
      "grit -> Stemmed: grit,LancasterStemmer: grit, Lemmatized: grit\n",
      "art -> Stemmed: art,LancasterStemmer: art, Lemmatized: art\n",
      "showing -> Stemmed: show,LancasterStemmer: show, Lemmatized: showing\n",
      "even -> Stemmed: even,LancasterStemmer: ev, Lemmatized: even\n",
      "hard -> Stemmed: hard,LancasterStemmer: hard, Lemmatized: hard\n",
      "days -> Stemmed: day,LancasterStemmer: day, Lemmatized: day\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer,LancasterStemmer,WordNetLemmatizer\n",
    "ps=PorterStemmer()\n",
    "ls=LancasterStemmer()\n",
    "lm=WordNetLemmatizer()\n",
    "for word in filtered_words:\n",
    "    print(f\"{word} -> Stemmed: {ps.stem(word)},LancasterStemmer: {ls.stem(word)}, Lemmatized: {lm.lemmatize(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86b9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ques 3\n",
    "import re\n",
    "\n",
    "text2 = \"The Gym is located at 1234 Sunset Blvd and offers 24/7 access. Members enjoy Cardio, Strength, and Flexibility training!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ea407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words more than 5 letters: ['located', 'Sunset', 'offers', 'access', 'Members', 'Cardio', 'Strength', 'Flexibility', 'training']\n",
      "numbers: ['1234', '24', '7']\n",
      "capitalized words: ['The', 'Gym', 'Sunset', 'Blvd', 'Members', 'Cardio', 'Strength', 'Flexibility']\n",
      "alphabet_only_words: ['The', 'Gym', 'is', 'located', 'at', 'Sunset', 'Blvd', 'and', 'offers', 'access', 'Members', 'enjoy', 'Cardio', 'Strength', 'and', 'Flexibility', 'training']\n",
      "vowel_words: ['is', 'at', 'and', 'offers', 'access', 'enjoy', 'and']\n"
     ]
    }
   ],
   "source": [
    "long_words=re.findall(r'\\b\\w{6,}\\b',text2)\n",
    "print(\"words more than 5 letters:\",long_words)\n",
    "numbers=re.findall(r'\\d+',text2)\n",
    "print(\"numbers:\",numbers)\n",
    "capitalized_words=re.findall(r'\\b[A-Z][a-zA-Z]*\\b',text2)\n",
    "print(\"capitalized words:\",capitalized_words)\n",
    "alphabet_words=re.findall(r'\\b[a-zA-Z]+\\b',text2)\n",
    "print(\"alphabet_only_words:\",alphabet_words)\n",
    "vowels=re.findall(r'\\b[aeiouAEIOU][a-zA-Z]*\\b',text2)\n",
    "print(\"vowel_words:\",vowels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549efa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'state-of-the-art', 'machine', \"doesn't\", 'make', 'mistakes', 'at', 'least', 'not', 'often', 'Its', 'accuracy', 'is', 'around', '99.9', 'which', 'isn', 't', 'bad', 'at', 'all', 'In', 'fact', 'it', 'solved', 'complex', 'equations', 'involving', '3.14', 'and', '42', 'in', 'seconds', 'Unlike', 'older', 'high-tech', 'systems', 'this', 'one', \"doesn't\", 'fail', 'under', 'pressure', 'By', '2025', \"it's\", 'expected', 'to', 'improve', 'by', 'at', 'least', '100']\n"
     ]
    }
   ],
   "source": [
    "text3=\"The state-of-the-art machine doesn't make mistakes—at least not often. Its accuracy is around 99.9%, which isn’t bad at all. In fact, it solved complex equations involving 3.14 and 42 in seconds! Unlike older high-tech systems, this one doesn't fail under pressure. By 2025, it's expected to improve by at least 100%.\"\n",
    "import re\n",
    "def custom_tokenizer(text):\n",
    "    pattern=r\"\\b(?:\\d+\\.\\d+|\\w+(?:[-']\\w+)*)\\b\" \n",
    "    tokens=re.findall(pattern,text)\n",
    "    return tokens\n",
    "tokens=custom_tokenizer(text3)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a502803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact us at <EMAIL> or visit our site <URL> for more info.\n",
      "You can also call us at <PHONE> or +91 9876543210. Alternatively, check <URL> or email <EMAIL>.\n"
     ]
    }
   ],
   "source": [
    "text4 = \"\"\"Contact us at support@example.com or visit our site https://example.com for more info.\n",
    "You can also call us at 123-456-7890 or +91 9876543210. Alternatively, check www.help-now.org or email john.doe23@mail.co.uk.\"\"\"\n",
    "import re\n",
    "## \\S= any non-white space character\n",
    "## + means more than one character\n",
    "def clean_text(text):\n",
    "    # replace email addresses\n",
    "    text=re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '<EMAIL>', text)\n",
    "    # replace URL'S (http,https,www)\n",
    "    text=re.sub(r'\\b(?:https?://|www\\.)\\S+\\b', '<URL>', text)\n",
    "    # replace phone numbers\n",
    "    text=re.sub(r'\\b(?:\\+91\\s?\\d{10}|\\d{3}-\\d{3}-\\d{4})\\b', '<PHONE>', text)\n",
    "    return text\n",
    "cleaned=clean_text(text4)\n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc56ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
